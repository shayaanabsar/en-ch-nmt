{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from os import path\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "\tdef __init__(self):\n",
    "\t\tself.vocabulary = set()\n",
    "\t\tself.stoi = {'<N>':0}\n",
    "\t\tself.itos = {0:'<N>'}\n",
    "\n",
    "\tdef add(self, v):\n",
    "\t\tif type(v) == str:\n",
    "\t\t\tself.vocabulary.add(v)\n",
    "\t\telif type(v) == list:\n",
    "\t\t\tself.vocabulary = self.vocabulary.union(set(v)) \n",
    "\n",
    "\tdef create_mappings(self):\n",
    "\t\tself.stoi |= {v:i+len(self.stoi) for i, v in enumerate(self.vocabulary)}\n",
    "\t\tself.itos |= {i+len(self.itos):v for i, v in enumerate(self.vocabulary)}\n",
    "\n",
    "\tdef encode(self, s): \n",
    "\t\treturn [self.stoi[c] for c in s]\n",
    "\t\n",
    "\tdef decode(self, i): \n",
    "\t\treturn [self.itos[n] for n in i]\n",
    "\t\n",
    "\n",
    "class PreProcessor:\n",
    "\tdef __init__(self):\n",
    "\t\tself.english_vocabulary = Vocabulary()\n",
    "\t\tself.cherokee_vocabulary = Vocabulary()\n",
    "\t\tself.cherokee = []\n",
    "\t\tself.english = []\n",
    "\t\tself.max_length = 0\n",
    "\t\tself.count = 0\n",
    "\n",
    "\tdef load_text(self, file_name):\n",
    "\t\tdata, language = [], file_name.split('.')[0]\n",
    "\n",
    "\t\twith open(path.join('chr_en_data', file_name)) as f:\n",
    "\t\t\tfor line in f.readlines():\n",
    "\t\t\t\tsentence = ['<S>'] + word_tokenize(line) + ['<E>']\n",
    "\n",
    "\t\t\t\tif language == 'en':\n",
    "\t\t\t\t\tself.english_vocabulary.add(sentence)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.cherokee_vocabulary.add(sentence)\n",
    "\n",
    "\t\t\t\tself.max_length = max(self.max_length, len(sentence))\n",
    "\t\t\t\tdata.append(sentence)\n",
    "\t\t\t\tself.count += 1 \n",
    "\t\treturn data\n",
    "\t\n",
    "\tdef get_data(self):\n",
    "\t\tcherokee = self.load_text('chr.txt')\n",
    "\t\tenglish  = self.load_text('en.txt' )\n",
    "\t\tassert len(cherokee) == len(english)\n",
    "\t\tself.cherokee += cherokee\n",
    "\t\tself.english  += english\n",
    "\n",
    "\t\treturn cherokee, english\n",
    "\n",
    "\t\n",
    "\tdef create_tensors(self):\n",
    "\t\tself.english_vocabulary.create_mappings()\n",
    "\t\tself.cherokee_vocabulary.create_mappings()\n",
    "\n",
    "\t\tenglish  = torch.zeros(size=(self.count//2, self.max_length), dtype=int)\n",
    "\t\tcherokee = torch.zeros(size=(self.count//2, self.max_length), dtype=int)\n",
    "\n",
    "\t\tfor i, sen in enumerate(self.english):\n",
    "\t\t\tfor j, v in enumerate(self.english_vocabulary.encode(sen)):\n",
    "\t\t\t\tenglish[i, j] = v\n",
    "\t\t\n",
    "\t\tfor i, sen in enumerate(self.cherokee):\n",
    "\t\t\tfor j, v in enumerate(self.cherokee_vocabulary.encode(sen)):\n",
    "\t\t\t\tcherokee[i, j] = v\n",
    "\n",
    "\t\tself.cherokee, self.english = cherokee, english\n",
    "\n",
    "\n",
    "preprocessor = PreProcessor()\n",
    "preprocessor.get_data()\n",
    "preprocessor.create_tensors()\n",
    "\n",
    "test = word_tokenize('ᎤᎵᎦᎵᏴᎮᎢ ᎠᏴᏤᏂ ᏫᎵᎻ.')\n",
    "\n",
    "assert preprocessor.cherokee_vocabulary.decode(preprocessor.cherokee_vocabulary.encode(test)) == test\n",
    "assert preprocessor.english.shape == preprocessor.cherokee.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cherokee Vocabulary Size: 12790\n",
      "English  Vocabulary Size: 6401\n"
     ]
    }
   ],
   "source": [
    "cherokee_vocab_size, english_vocab_size = len(preprocessor.cherokee_vocabulary.stoi), len(preprocessor.english_vocabulary.stoi)\n",
    "\n",
    "print(f'Cherokee Vocabulary Size: {cherokee_vocab_size}')\n",
    "print(f'English  Vocabulary Size: {english_vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75406, 106])\n",
      "torch.Size([75406, 106])\n",
      "torch.Size([75406, 6401])\n"
     ]
    }
   ],
   "source": [
    "cherokee_in, english_in, expected_probabilities = [], [], []\n",
    "\n",
    "for i, c in enumerate(preprocessor.cherokee):\n",
    "\tcherokee_tensor = torch.tensor(list(c))\n",
    "\tfor j in range(1, preprocessor.max_length - 1):\n",
    "\t\tenglish_tensor = torch.zeros(preprocessor.max_length)\n",
    "\t\tenglish_tensor[:j] = preprocessor.english[i, :j]\n",
    "\t\t\n",
    "\t\tprobability = torch.zeros(english_vocab_size)\n",
    "\t\tprobability[preprocessor.english[i, j].item()] = 1\n",
    "\t\tif preprocessor.english[i, j].item() != 0:\n",
    "\t\t\tcherokee_in.append(cherokee_tensor)\n",
    "\t\t\tenglish_in.append(english_tensor)\n",
    "\t\t\texpected_probabilities.append(probability)\n",
    "\n",
    "\n",
    "cherokee, english, expected_probabilities = torch.stack(cherokee_in).int(), torch.stack(english_in).int(), torch.stack(expected_probabilities).float()\n",
    "\n",
    "print(cherokee.shape)\n",
    "print(english.shape)\n",
    "print(expected_probabilities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(cherokee.shape[0])\n",
    "\n",
    "train_cherokee = cherokee[:int(0.8*size)]\n",
    "train_english  = english[:int(0.8*size)]\n",
    "train_probabilities = expected_probabilities[:int(0.8*size)]\n",
    "\n",
    "test_cherokee  = cherokee[int(0.8*size):int(0.9*size)]\n",
    "test_english   = english[int(0.8*size):int(0.9*size)]\n",
    "test_probabilities = expected_probabilities[int(0.8*size):int(0.9*size)]\n",
    "\n",
    "val_cherokee   = cherokee[int(0.9*size):]\n",
    "val_english    = english[int(0.9*size):]\n",
    "val_probabilities = expected_probabilities[int(0.9*size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(train_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSIONS = 64\n",
    "QKV_DIMENSIONS       = 64\n",
    "SEQUENCE_LENGTH      = preprocessor.max_length\n",
    "ATTENTION_HEADS      = 4\n",
    "DECODERS             = 4\n",
    "ENCODERS             = 4\n",
    "BATCH_SIZE           = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0723, -1.3801,  0.0585,  ..., -0.4914,  0.5458, -0.0301],\n",
      "        [-0.2896, -1.0054,  0.6750,  ...,  0.0719, -0.1699,  0.0991],\n",
      "        [-0.2460,  1.2158,  0.6026,  ..., -0.5683, -0.3942, -1.3164],\n",
      "        ...,\n",
      "        [-0.4786, -0.1223, -0.6923,  ...,  0.1017,  0.1417, -0.1078],\n",
      "        [-2.2747, -0.4283,  0.7588,  ...,  0.5555,  0.4130, -0.6876],\n",
      "        [-1.1190,  1.0133, -0.8959,  ..., -0.8756, -0.1275, -0.6334]])\n",
      "tensor([[-1.0723,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "        [-0.2896, -1.0054,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "        [-0.2460,  1.2158,  0.6026,  ...,    -inf,    -inf,    -inf],\n",
      "        ...,\n",
      "        [-0.4786, -0.1223, -0.6923,  ...,  0.1017,    -inf,    -inf],\n",
      "        [-2.2747, -0.4283,  0.7588,  ...,  0.5555,  0.4130,    -inf],\n",
      "        [-1.1190,  1.0133, -0.8959,  ..., -0.8756, -0.1275, -0.6334]])\n"
     ]
    }
   ],
   "source": [
    "def mask_tensor(t):\n",
    "\tmask = torch.tril(torch.ones(size=(t.shape)))\n",
    "\tmask[mask==0], mask[mask==1] = float('-inf'), 0\n",
    "\t\n",
    "\treturn t + mask\n",
    "\n",
    "test = torch.randn(SEQUENCE_LENGTH, SEQUENCE_LENGTH)\n",
    "print(test)\n",
    "print(mask_tensor(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0989, -0.0104,  0.1618,  ..., -0.0822, -0.0214, -0.1309],\n",
      "         [ 0.1341, -0.1206,  0.1161,  ..., -0.0746,  0.0038, -0.1836],\n",
      "         [ 0.0848, -0.0751,  0.1078,  ..., -0.0734, -0.0183, -0.1206],\n",
      "         ...,\n",
      "         [ 0.0727, -0.1055,  0.0839,  ..., -0.0682, -0.0305, -0.1725],\n",
      "         [ 0.1381, -0.1461,  0.0984,  ..., -0.0862, -0.0456, -0.1389],\n",
      "         [ 0.1092, -0.0757,  0.1450,  ..., -0.0619, -0.0086, -0.1633]],\n",
      "\n",
      "        [[ 0.0615, -0.0477,  0.0428,  ..., -0.0960, -0.0376, -0.1159],\n",
      "         [ 0.0571, -0.0400,  0.1615,  ..., -0.0946,  0.0134, -0.1306],\n",
      "         [ 0.1336, -0.0750,  0.1912,  ..., -0.0752,  0.0421, -0.1661],\n",
      "         ...,\n",
      "         [ 0.1189, -0.0608,  0.1153,  ..., -0.1013, -0.0057, -0.1614],\n",
      "         [ 0.1168, -0.0460,  0.1086,  ..., -0.0842, -0.0174, -0.1716],\n",
      "         [ 0.1043, -0.0606,  0.1712,  ..., -0.1196,  0.0169, -0.1200]],\n",
      "\n",
      "        [[ 0.1384, -0.0572,  0.1658,  ..., -0.0829,  0.0125, -0.1179],\n",
      "         [ 0.1133, -0.1130,  0.0573,  ..., -0.0744,  0.0243, -0.1728],\n",
      "         [ 0.1041, -0.1130,  0.1574,  ..., -0.0624, -0.0228, -0.1290],\n",
      "         ...,\n",
      "         [ 0.0696, -0.0424,  0.1936,  ..., -0.1058,  0.0026, -0.1342],\n",
      "         [ 0.0570, -0.0794,  0.1148,  ..., -0.0802,  0.0375, -0.1599],\n",
      "         [ 0.0990, -0.0444,  0.0945,  ..., -0.1024,  0.0226, -0.1357]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0594, -0.0812,  0.0650,  ..., -0.1235,  0.0089, -0.1565],\n",
      "         [ 0.0764, -0.0783,  0.0763,  ..., -0.1270, -0.0060, -0.1540],\n",
      "         [ 0.1156, -0.0582,  0.1189,  ..., -0.1040,  0.0089, -0.1423],\n",
      "         ...,\n",
      "         [ 0.0466, -0.0398,  0.1075,  ..., -0.1337,  0.0626, -0.1668],\n",
      "         [ 0.0439, -0.0666,  0.1685,  ..., -0.0834,  0.0251, -0.1657],\n",
      "         [ 0.1000, -0.0747,  0.0954,  ..., -0.0928, -0.0042, -0.1389]],\n",
      "\n",
      "        [[ 0.1779, -0.0491,  0.0901,  ..., -0.1517,  0.0130, -0.1471],\n",
      "         [ 0.1318, -0.0779,  0.0991,  ..., -0.0979, -0.0253, -0.1568],\n",
      "         [ 0.0971, -0.1057,  0.1413,  ..., -0.0498,  0.0243, -0.1537],\n",
      "         ...,\n",
      "         [ 0.1581, -0.0937,  0.1683,  ..., -0.0600, -0.0597, -0.1595],\n",
      "         [ 0.1024, -0.0485,  0.1444,  ..., -0.1261,  0.0279, -0.1451],\n",
      "         [ 0.1045, -0.0953,  0.0548,  ..., -0.0913,  0.0005, -0.1709]],\n",
      "\n",
      "        [[ 0.1015, -0.0780,  0.0906,  ..., -0.0662, -0.0189, -0.1805],\n",
      "         [ 0.0920, -0.0339,  0.1396,  ..., -0.0851, -0.0219, -0.1186],\n",
      "         [ 0.1300, -0.0745,  0.0790,  ..., -0.1252,  0.0011, -0.1670],\n",
      "         ...,\n",
      "         [ 0.0941, -0.0620,  0.1469,  ..., -0.0939, -0.0094, -0.1821],\n",
      "         [ 0.0980, -0.0778,  0.1013,  ..., -0.1309,  0.0056, -0.1530],\n",
      "         [ 0.0914, -0.0722,  0.0995,  ..., -0.0982, -0.0266, -0.1122]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "\tdef __init__(self, masked=False):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.obtain_key   = nn.Linear(EMBEDDING_DIMENSIONS, QKV_DIMENSIONS)\n",
    "\t\tself.obtain_query = nn.Linear(EMBEDDING_DIMENSIONS, QKV_DIMENSIONS)\n",
    "\t\tself.obtain_value = nn.Linear(EMBEDDING_DIMENSIONS, QKV_DIMENSIONS)\n",
    "\t\tself.masked = masked\n",
    "\n",
    "\tdef forward(self, data, encoder_output=None):\n",
    "\t\tif encoder_output is None: Q, K, V = self.obtain_query(data), self.obtain_key(data), self.obtain_value(data)\n",
    "\t\telse: Q, K, V = self.obtain_query(data), self.obtain_key(encoder_output), self.obtain_value(encoder_output)\n",
    "\t\tmat_mul = Q @ K.transpose(-2, -1)\n",
    "\t\tscaled_mat_mul = mat_mul / sqrt(QKV_DIMENSIONS)\n",
    "\t\tif self.masked: scaled_mat_mul = mask_tensor(scaled_mat_mul)\n",
    "\t\tsoftmax_mat_mul = torch.softmax(scaled_mat_mul, dim=-1)\n",
    "\t\toutput = softmax_mat_mul @ V\n",
    "\n",
    "\t\treturn output\n",
    "\n",
    "test, e_output = torch.randn(size=(BATCH_SIZE, SEQUENCE_LENGTH, EMBEDDING_DIMENSIONS)), torch.randn(size=(SEQUENCE_LENGTH, QKV_DIMENSIONS))\n",
    "test_module = AttentionHead()\n",
    "print(test_module(test, encoder_output=e_output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0532,  0.0134,  0.1116,  ...,  0.0125,  0.0692,  0.0140],\n",
      "         [ 0.0386,  0.0033,  0.1562,  ...,  0.0127,  0.0414,  0.0259],\n",
      "         [ 0.0296,  0.0150,  0.1250,  ..., -0.0055,  0.0707,  0.0118],\n",
      "         ...,\n",
      "         [ 0.0437, -0.0078,  0.0705,  ..., -0.0169,  0.0904, -0.0044],\n",
      "         [ 0.0256,  0.0057,  0.1296,  ..., -0.0132,  0.0663, -0.0025],\n",
      "         [ 0.0096, -0.0156,  0.0901,  ..., -0.0201,  0.0468, -0.0008]],\n",
      "\n",
      "        [[-0.0643,  0.0159,  0.0075,  ..., -0.0311,  0.0794,  0.0495],\n",
      "         [-0.0438,  0.0520, -0.0041,  ...,  0.0014,  0.1282, -0.0014],\n",
      "         [-0.0367,  0.0219,  0.0074,  ..., -0.0519,  0.1044,  0.0416],\n",
      "         ...,\n",
      "         [-0.0579,  0.0092,  0.0304,  ..., -0.0280,  0.1106,  0.0095],\n",
      "         [-0.0696,  0.0053, -0.0124,  ..., -0.0529,  0.0528,  0.0436],\n",
      "         [-0.0518,  0.0267,  0.0208,  ..., -0.0157,  0.1136,  0.0484]],\n",
      "\n",
      "        [[-0.0551,  0.0543,  0.0953,  ..., -0.0137,  0.0985,  0.0387],\n",
      "         [-0.0426,  0.0377,  0.0651,  ..., -0.0724,  0.1163,  0.0009],\n",
      "         [-0.0285,  0.0271,  0.1098,  ..., -0.0068,  0.0565,  0.0682],\n",
      "         ...,\n",
      "         [-0.0433,  0.0498,  0.0883,  ..., -0.0219,  0.0718,  0.0533],\n",
      "         [-0.0558,  0.0475,  0.1000,  ..., -0.0581,  0.1083,  0.0268],\n",
      "         [-0.0475,  0.0424,  0.0659,  ..., -0.0388,  0.0660,  0.0197]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0835,  0.0893,  0.0464,  ..., -0.0915,  0.0650,  0.0195],\n",
      "         [-0.0698,  0.0863,  0.0201,  ..., -0.1059,  0.0103,  0.0234],\n",
      "         [-0.0293,  0.0715,  0.0232,  ..., -0.0492,  0.0584,  0.0069],\n",
      "         ...,\n",
      "         [-0.0238,  0.0535,  0.0401,  ..., -0.0813,  0.0228,  0.0678],\n",
      "         [-0.0501,  0.0619,  0.0094,  ..., -0.0551,  0.0322,  0.0243],\n",
      "         [-0.0490,  0.0835, -0.0031,  ..., -0.0738,  0.0338,  0.0246]],\n",
      "\n",
      "        [[ 0.0008,  0.0772,  0.0925,  ..., -0.0400,  0.0526,  0.0673],\n",
      "         [-0.0178,  0.0844,  0.0706,  ..., -0.0377,  0.0665,  0.0786],\n",
      "         [-0.0239,  0.0853,  0.0559,  ..., -0.0386,  0.0321,  0.1002],\n",
      "         ...,\n",
      "         [-0.0019,  0.0764,  0.0425,  ..., -0.0433,  0.0064,  0.0756],\n",
      "         [ 0.0009,  0.0837,  0.0224,  ..., -0.0242,  0.0572,  0.0717],\n",
      "         [-0.0150,  0.1060,  0.0338,  ..., -0.0504,  0.0431,  0.0683]],\n",
      "\n",
      "        [[-0.0183,  0.0646,  0.0802,  ..., -0.0245,  0.0425,  0.0366],\n",
      "         [-0.0060,  0.0504,  0.0734,  ...,  0.0359,  0.0262,  0.0270],\n",
      "         [ 0.0038,  0.0196,  0.0494,  ...,  0.0449,  0.0373,  0.0037],\n",
      "         ...,\n",
      "         [-0.0364,  0.0426,  0.0577,  ..., -0.0008,  0.0095,  0.0063],\n",
      "         [-0.0116,  0.0469,  0.0947,  ..., -0.0167,  0.0371,  0.0271],\n",
      "         [-0.0234,  0.0359,  0.0691,  ...,  0.0057,  0.0439,  0.0155]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "\tdef __init__(self, masked=False):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.heads  = [AttentionHead(masked=masked) for _ in range(ATTENTION_HEADS)]\n",
    "\t\tself.linear = nn.Linear(EMBEDDING_DIMENSIONS*ATTENTION_HEADS, EMBEDDING_DIMENSIONS)\n",
    "\n",
    "\tdef forward(self, data, encoder_output=None):\n",
    "\t\tvectors = torch.cat([head(data, encoder_output=encoder_output) for head in self.heads], dim=-1)\n",
    "\t\treturn self.linear(vectors)\n",
    "\t\n",
    "\n",
    "test = torch.randn(size=(BATCH_SIZE, SEQUENCE_LENGTH, EMBEDDING_DIMENSIONS))\n",
    "test_module = MultiHeadedAttention()\n",
    "print(test_module(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-7.1829e-02, -4.0354e-02,  2.8878e-03,  ..., -1.2242e-01,\n",
      "           9.5087e-02,  4.0177e-01],\n",
      "         [ 1.9630e-02, -8.6136e-03, -1.8324e-01,  ...,  1.7885e-03,\n",
      "           8.6181e-02,  7.6331e-02],\n",
      "         [-6.2632e-02,  2.2289e-01, -1.9254e-01,  ..., -1.8628e-01,\n",
      "           3.6278e-01,  1.3920e-01],\n",
      "         ...,\n",
      "         [-1.3837e-01, -5.0365e-02,  2.5320e-01,  ..., -9.7182e-02,\n",
      "           2.9252e-02,  1.1883e-01],\n",
      "         [ 3.6318e-01, -1.4389e-02,  1.4974e-01,  ..., -1.5681e-01,\n",
      "           2.2288e-01, -1.2608e-01],\n",
      "         [ 3.4192e-02, -6.1767e-02,  3.1173e-02,  ...,  8.6230e-02,\n",
      "          -2.6353e-02, -5.5832e-02]],\n",
      "\n",
      "        [[ 3.9902e-01,  3.0212e-01,  3.9483e-02,  ..., -1.9250e-01,\n",
      "           3.0337e-01,  3.9445e-02],\n",
      "         [ 4.4717e-02,  1.1588e-01, -1.1071e-01,  ..., -8.8618e-02,\n",
      "           8.8362e-02, -9.9734e-02],\n",
      "         [ 7.6705e-02, -5.0363e-02,  4.4998e-02,  ..., -1.3614e-02,\n",
      "           4.6928e-01, -1.7085e-01],\n",
      "         ...,\n",
      "         [ 1.8555e-01, -9.5743e-02,  2.0291e-02,  ..., -4.1430e-01,\n",
      "          -3.6803e-01,  5.9836e-03],\n",
      "         [ 3.9047e-01, -1.5056e-01,  3.8924e-02,  ..., -2.4602e-01,\n",
      "           3.8062e-01, -2.1057e-02],\n",
      "         [ 3.5281e-01, -5.9769e-02,  3.7394e-01,  ..., -4.1732e-01,\n",
      "          -2.3158e-01,  2.5217e-01]],\n",
      "\n",
      "        [[-7.3606e-02,  9.4743e-02, -3.0943e-02,  ..., -4.2259e-01,\n",
      "           1.0132e-01,  3.8894e-01],\n",
      "         [-2.6505e-01,  1.3138e-01,  2.4554e-01,  ...,  7.4512e-02,\n",
      "           2.4331e-01,  2.5224e-01],\n",
      "         [ 1.6906e-01, -5.8489e-02,  1.4764e-01,  ...,  4.1785e-01,\n",
      "           2.4442e-01, -2.8081e-01],\n",
      "         ...,\n",
      "         [ 8.5224e-02, -1.0792e-01,  6.0704e-02,  ..., -4.8771e-01,\n",
      "          -1.8916e-01, -1.4573e-01],\n",
      "         [ 1.4722e-01,  3.6985e-01, -2.7004e-02,  ..., -6.2400e-02,\n",
      "           1.7146e-03, -8.4540e-02],\n",
      "         [ 7.6022e-02,  1.0176e-01,  1.2796e-01,  ..., -1.8861e-01,\n",
      "          -4.8120e-02,  4.0597e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.7153e-02, -2.8073e-02, -1.4981e-01,  ...,  1.3378e-01,\n",
      "           3.4251e-01, -2.1070e-02],\n",
      "         [ 4.1326e-03, -1.3729e-01, -4.3773e-02,  ..., -1.7193e-01,\n",
      "           3.5569e-02,  4.3371e-01],\n",
      "         [-2.4060e-02, -7.0166e-02,  2.6407e-03,  ...,  8.8998e-03,\n",
      "           2.5931e-02,  3.2291e-01],\n",
      "         ...,\n",
      "         [-2.1489e-01, -8.6934e-02, -4.0256e-01,  ..., -2.5143e-01,\n",
      "          -1.0579e-01,  3.8597e-04],\n",
      "         [ 2.9946e-02, -4.7493e-01,  7.4941e-02,  ..., -3.0972e-01,\n",
      "           4.4352e-02,  2.3423e-01],\n",
      "         [ 3.4436e-01, -2.8401e-01, -1.3922e-02,  ...,  1.1403e-01,\n",
      "          -2.9688e-01,  4.1219e-02]],\n",
      "\n",
      "        [[ 7.2415e-02,  1.1756e-01,  1.4397e-02,  ..., -1.8119e-01,\n",
      "          -7.1427e-02,  3.1704e-01],\n",
      "         [ 3.4591e-01,  3.1067e-01, -1.9895e-01,  ..., -4.3311e-01,\n",
      "           3.4806e-01, -2.4920e-02],\n",
      "         [ 1.8565e-01, -4.7532e-01, -2.0849e-01,  ..., -4.4807e-01,\n",
      "          -2.5594e-01, -1.7067e-02],\n",
      "         ...,\n",
      "         [ 1.8660e-01, -6.6398e-02,  1.6175e-02,  ..., -2.1433e-02,\n",
      "          -4.9368e-02,  1.6552e-02],\n",
      "         [ 3.8375e-02, -3.7541e-02, -9.7267e-02,  ..., -2.3306e-01,\n",
      "          -2.7456e-01, -1.0412e-01],\n",
      "         [ 4.7050e-01, -1.9480e-01, -2.6355e-01,  ...,  1.0205e-01,\n",
      "          -3.9638e-03, -3.2894e-02]],\n",
      "\n",
      "        [[ 7.5149e-02, -5.1075e-01,  2.6416e-01,  ..., -2.9855e-01,\n",
      "          -1.8834e-01, -2.3139e-01],\n",
      "         [ 6.3148e-01, -2.0794e-01,  3.3138e-02,  ..., -5.8382e-01,\n",
      "          -1.9530e-01,  1.0219e-01],\n",
      "         [ 1.9324e-01, -1.4030e-01, -2.3998e-01,  ..., -4.9117e-01,\n",
      "          -1.3792e-02,  1.8621e-02],\n",
      "         ...,\n",
      "         [ 3.6377e-01, -2.4047e-01,  5.4488e-02,  ...,  1.7487e-01,\n",
      "           3.4729e-01,  1.1809e-01],\n",
      "         [ 1.0879e-01, -5.5163e-01,  1.2212e-01,  ...,  2.3501e-01,\n",
      "          -1.0244e-01,  1.8774e-01],\n",
      "         [ 1.9014e-02, -2.6267e-01, -2.1574e-01,  ...,  1.3959e-01,\n",
      "           1.0679e-01,  1.2732e-01]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.network = nn.Sequential(\n",
    "\t\t\tnn.Linear(EMBEDDING_DIMENSIONS, EMBEDDING_DIMENSIONS),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(EMBEDDING_DIMENSIONS, EMBEDDING_DIMENSIONS)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, data):\n",
    "\t\treturn self.network(data)\n",
    "\n",
    "test = torch.randn(size=(BATCH_SIZE, SEQUENCE_LENGTH, EMBEDDING_DIMENSIONS))\n",
    "test_module = FeedForward()\n",
    "print(test_module(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.1378e+00,  2.2594e+00, -8.9774e-01,  ..., -3.9347e-01,\n",
      "          -1.3277e-01, -1.1951e-01],\n",
      "         [-1.1793e+00, -4.7634e-01,  7.8327e-01,  ...,  6.8740e-01,\n",
      "           9.9575e-02, -1.1034e-01],\n",
      "         [ 1.1214e+00,  9.1023e-01, -9.4066e-01,  ..., -4.2511e-01,\n",
      "          -2.5348e-01, -6.8145e-01],\n",
      "         ...,\n",
      "         [ 1.2117e+00,  6.7151e-01,  9.5772e-01,  ..., -1.0077e-01,\n",
      "           1.0680e-01, -1.4099e+00],\n",
      "         [ 1.8021e+00,  2.0497e-01,  2.2148e+00,  ..., -1.1103e-01,\n",
      "           8.5511e-01,  1.2522e+00],\n",
      "         [ 5.0089e-02, -5.1241e-01, -1.2340e+00,  ..., -3.7484e-01,\n",
      "          -2.7225e-02,  5.5570e-01]],\n",
      "\n",
      "        [[-1.3226e+00, -6.2207e-01,  5.3128e-01,  ...,  2.4155e-02,\n",
      "           1.4907e+00, -9.8801e-02],\n",
      "         [ 1.0117e-02, -1.2984e+00, -1.8277e+00,  ..., -1.7832e-01,\n",
      "          -2.6286e-01,  1.2925e+00],\n",
      "         [ 5.8895e-01,  5.8580e-01, -3.5561e-02,  ...,  2.8899e-01,\n",
      "           9.9369e-01, -1.3183e-01],\n",
      "         ...,\n",
      "         [-2.0359e+00,  1.0019e+00, -4.1859e-01,  ...,  3.1865e-01,\n",
      "          -6.8680e-01,  5.0524e-01],\n",
      "         [-2.7441e-01,  1.1868e-01, -1.0168e+00,  ...,  2.1123e+00,\n",
      "          -6.3032e-01,  6.6089e-01],\n",
      "         [ 3.6372e-01,  1.0687e-01,  3.8458e-01,  ...,  9.2234e-01,\n",
      "          -1.0170e+00,  1.2177e+00]],\n",
      "\n",
      "        [[-2.2125e+00, -1.1168e+00, -5.4525e-01,  ...,  3.5044e-01,\n",
      "           1.3297e-04, -8.8135e-01],\n",
      "         [ 5.1741e-01,  3.6263e-01, -3.9689e-01,  ..., -1.7362e+00,\n",
      "           9.1075e-01, -2.1357e+00],\n",
      "         [-4.7559e-02,  8.0171e-01, -8.5675e-01,  ...,  9.5583e-01,\n",
      "          -7.0123e-01, -1.1764e+00],\n",
      "         ...,\n",
      "         [ 7.9347e-01,  1.8730e+00, -2.0579e-02,  ..., -5.5117e-01,\n",
      "          -5.7080e-01, -1.0910e+00],\n",
      "         [-8.8693e-01, -5.6020e-01, -2.0786e-01,  ..., -7.2431e-01,\n",
      "           1.5253e+00,  3.8197e-01],\n",
      "         [-1.2804e+00,  2.4977e+00,  3.8929e-01,  ...,  2.7706e-01,\n",
      "          -1.0590e+00, -1.6014e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0667e+00,  3.0075e-01, -4.6367e-01,  ...,  6.9716e-01,\n",
      "           4.0468e-03,  9.0163e-01],\n",
      "         [-8.5433e-01, -6.9860e-01,  8.4267e-02,  ...,  1.3552e+00,\n",
      "           2.3544e-01,  1.5976e+00],\n",
      "         [-7.8537e-01,  4.9487e-01,  1.9803e-01,  ...,  3.3734e-01,\n",
      "           9.8048e-02,  1.7492e-01],\n",
      "         ...,\n",
      "         [ 1.3277e+00,  5.8529e-02, -5.0960e-01,  ..., -1.2068e+00,\n",
      "          -1.0645e+00, -5.6602e-01],\n",
      "         [-7.3447e-01,  2.8078e-02,  7.1946e-01,  ..., -3.5316e-01,\n",
      "           2.3485e-01, -1.1605e+00],\n",
      "         [ 1.2214e+00,  1.1325e+00,  8.6428e-01,  ..., -8.9786e-01,\n",
      "           5.1187e-01, -1.3364e+00]],\n",
      "\n",
      "        [[-1.0328e+00,  4.9289e-01,  4.4275e-01,  ..., -6.4924e-01,\n",
      "          -4.3336e-02,  1.8475e+00],\n",
      "         [ 1.2717e+00, -7.3160e-01,  1.3894e-01,  ...,  8.4689e-01,\n",
      "           5.3987e-01, -4.3378e-01],\n",
      "         [ 9.5841e-02, -5.4850e-01,  6.0793e-01,  ..., -6.5680e-01,\n",
      "          -7.3708e-01,  3.6198e-01],\n",
      "         ...,\n",
      "         [-7.6487e-01, -1.5697e+00,  4.9800e-01,  ..., -1.2379e+00,\n",
      "           5.1710e-01,  1.3597e+00],\n",
      "         [-7.6501e-01, -1.6781e+00, -7.6440e-01,  ..., -1.2399e-01,\n",
      "           1.4331e+00, -1.0274e+00],\n",
      "         [ 1.6660e+00, -1.5783e+00, -1.0598e+00,  ..., -5.8867e-01,\n",
      "           2.4833e-01, -5.9659e-01]],\n",
      "\n",
      "        [[ 1.4718e+00, -1.9380e-02, -6.0931e-01,  ...,  2.3101e+00,\n",
      "          -3.0360e-01,  1.9419e+00],\n",
      "         [-7.2431e-01,  1.1384e-01,  4.6843e-01,  ..., -5.5236e-01,\n",
      "          -6.1532e-01,  1.0837e-01],\n",
      "         [ 8.3286e-01, -3.9415e-01, -3.1506e-01,  ...,  1.4648e+00,\n",
      "          -2.8295e-01, -1.4393e+00],\n",
      "         ...,\n",
      "         [ 2.7359e-01,  5.6520e-02,  1.6252e+00,  ..., -1.1124e+00,\n",
      "           1.0078e+00,  7.0760e-01],\n",
      "         [ 1.8962e+00,  1.4193e+00, -1.2218e+00,  ...,  6.0737e-01,\n",
      "          -1.0475e+00,  5.3084e-01],\n",
      "         [-1.4734e+00,  5.2802e-01, -2.4637e-01,  ...,  1.3558e+00,\n",
      "           1.3958e+00,  6.9841e-01]]])\n",
      "tensor([[[ 2.5277e+00,  9.5110e-02, -4.4646e-01,  ..., -1.0525e+00,\n",
      "          -2.6669e+00, -8.1788e-01],\n",
      "         [-2.4833e-01, -1.4836e+00,  1.4632e+00,  ..., -6.1756e-01,\n",
      "          -2.1987e+00,  3.9721e-01],\n",
      "         [ 1.2034e+00,  4.3850e-02, -1.0030e+00,  ..., -9.0418e-01,\n",
      "          -1.9190e+00, -7.0353e-01],\n",
      "         ...,\n",
      "         [ 1.4163e+00,  7.2276e-01,  9.3584e-01,  ...,  3.7459e-01,\n",
      "          -1.1816e+00, -1.9678e+00],\n",
      "         [ 3.5059e+00, -5.7974e-01,  2.7203e+00,  ..., -6.0515e-01,\n",
      "          -8.7750e-01,  1.3340e+00],\n",
      "         [ 7.6590e-01, -1.4303e+00, -1.1771e+00,  ..., -7.5529e-01,\n",
      "          -1.2804e+00, -1.0619e+00]],\n",
      "\n",
      "        [[ 6.4619e-01, -8.9720e-01,  7.3243e-01,  ...,  1.8143e+00,\n",
      "          -1.1959e+00, -1.9104e-01],\n",
      "         [ 1.2809e+00, -1.6321e+00, -2.8142e+00,  ...,  3.9868e-01,\n",
      "          -3.3290e+00,  9.6962e-01],\n",
      "         [ 1.2058e+00, -1.2285e+00, -8.9110e-01,  ...,  6.9316e-01,\n",
      "          -2.4973e+00, -3.7153e-01],\n",
      "         ...,\n",
      "         [-2.7179e-01,  7.1591e-01,  5.9165e-01,  ...,  2.0597e+00,\n",
      "          -3.4037e+00, -2.5758e-01],\n",
      "         [ 1.1536e+00, -1.0026e+00, -1.5628e+00,  ...,  3.3952e+00,\n",
      "          -3.7451e+00, -8.2684e-01],\n",
      "         [ 1.6680e+00,  2.9920e-01,  1.1325e+00,  ...,  2.1162e+00,\n",
      "          -3.3197e+00, -5.9823e-01]],\n",
      "\n",
      "        [[-1.3217e+00, -2.0890e+00,  6.9617e-01,  ...,  1.2210e-01,\n",
      "          -1.9296e+00, -3.4437e-01],\n",
      "         [ 1.7021e+00, -8.8785e-01,  7.6128e-01,  ..., -1.1926e+00,\n",
      "          -1.6501e+00, -1.2883e+00],\n",
      "         [ 2.0302e+00, -2.5457e-01, -3.8093e-01,  ...,  1.1120e+00,\n",
      "          -2.3799e+00, -2.0731e+00],\n",
      "         ...,\n",
      "         [ 1.9623e+00,  7.2941e-01,  1.0066e+00,  ..., -1.0933e-01,\n",
      "          -3.7889e+00,  2.4150e-01],\n",
      "         [ 7.7616e-01, -2.1675e+00,  1.0723e+00,  ..., -6.6676e-01,\n",
      "          -6.5010e-01,  8.2456e-01],\n",
      "         [-4.7857e-01,  6.3850e-01,  7.8831e-01,  ..., -1.5396e-01,\n",
      "          -3.9959e+00, -1.6516e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.0715e-01,  9.5355e-01, -1.3850e+00,  ...,  1.9100e+00,\n",
      "          -2.1934e+00,  7.6402e-01],\n",
      "         [ 8.1345e-01, -8.4013e-01,  9.5998e-01,  ...,  3.1632e+00,\n",
      "          -1.2050e+00, -1.2790e-01],\n",
      "         [ 7.2368e-01,  5.7542e-01,  8.3821e-02,  ...,  2.1441e+00,\n",
      "          -2.6789e+00,  9.6037e-01],\n",
      "         ...,\n",
      "         [ 2.1461e+00, -3.9285e-01, -9.1498e-01,  ...,  7.7452e-01,\n",
      "          -4.1904e+00, -1.3678e-01],\n",
      "         [ 9.3720e-01, -9.1805e-01,  1.9584e-01,  ...,  1.3991e+00,\n",
      "          -2.4177e+00, -1.3268e+00],\n",
      "         [ 2.0732e+00,  8.8340e-01,  1.0352e+00,  ..., -1.4157e-01,\n",
      "          -2.3726e+00, -2.6735e+00]],\n",
      "\n",
      "        [[-3.9751e-01, -2.8265e-01,  1.8867e+00,  ...,  5.2807e-01,\n",
      "          -1.2602e+00,  2.8479e+00],\n",
      "         [ 2.2271e+00, -1.0475e+00,  9.2120e-01,  ...,  1.5275e+00,\n",
      "          -2.1062e+00, -1.2213e-01],\n",
      "         [ 1.1294e+00, -6.6232e-01,  1.2816e+00,  ...,  7.1008e-01,\n",
      "          -2.1711e+00,  1.9623e-01],\n",
      "         ...,\n",
      "         [ 6.6673e-01, -2.0819e+00,  8.7992e-01,  ..., -5.6863e-01,\n",
      "          -5.4690e-01,  1.4370e+00],\n",
      "         [ 3.2697e-01, -1.9836e+00,  5.2519e-01,  ...,  1.2513e+00,\n",
      "           9.6928e-01, -3.4606e-01],\n",
      "         [ 2.5509e+00, -7.5001e-01, -1.7859e+00,  ..., -3.5727e-02,\n",
      "          -4.3273e-01, -1.8211e+00]],\n",
      "\n",
      "        [[ 2.0408e+00,  5.3919e-02,  6.4292e-01,  ...,  2.7583e+00,\n",
      "          -2.7062e+00,  1.9177e+00],\n",
      "         [ 7.9513e-01,  1.7020e-01,  8.6419e-01,  ...,  1.5605e-01,\n",
      "          -3.5814e+00,  1.3213e+00],\n",
      "         [ 1.6132e+00, -4.1428e-01, -1.2072e+00,  ...,  2.7236e+00,\n",
      "          -3.6782e+00, -3.4768e-01],\n",
      "         ...,\n",
      "         [ 1.9175e+00,  1.7748e-01,  2.0567e+00,  ...,  5.9350e-01,\n",
      "          -2.2380e+00,  1.6370e+00],\n",
      "         [ 3.0957e+00,  4.7991e-01, -2.1762e+00,  ...,  1.5822e+00,\n",
      "          -4.0374e+00,  1.3452e-01],\n",
      "         [-1.1179e-03,  1.8167e-01,  3.2243e-01,  ...,  2.6719e+00,\n",
      "          -2.4960e+00,  1.1105e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.multi_headed_attention = MultiHeadedAttention()\n",
    "\t\tself.norm1 = nn.LayerNorm(EMBEDDING_DIMENSIONS)\n",
    "\t\tself.feed_forward = FeedForward()\n",
    "\t\tself.norm2 = nn.LayerNorm(EMBEDDING_DIMENSIONS)\n",
    "\n",
    "\tdef forward(self, data):\n",
    "\t\tattention_vectors = self.multi_headed_attention(data)\n",
    "\t\tnormalised = self.norm1(attention_vectors) + data # Residual Connection\n",
    "\t\tfed_through = self.feed_forward(normalised)\n",
    "\t\tnormalised_2 = self.norm2(fed_through) + normalised\n",
    "\n",
    "\t\treturn normalised_2\n",
    "\t\n",
    "test = torch.randn(size=(BATCH_SIZE, SEQUENCE_LENGTH, EMBEDDING_DIMENSIONS))\n",
    "print(test)\n",
    "test_module = Encoder()\n",
    "print(test_module(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.2642,  5.4909,  2.0919,  ..., -1.5268,  2.8451,  0.6862],\n",
      "         [ 1.0624,  2.7324,  3.4598,  ...,  1.3091,  2.2959,  2.8245],\n",
      "         [-0.0172,  5.6192,  2.8797,  ...,  1.8983,  2.1877,  2.6392],\n",
      "         ...,\n",
      "         [ 0.1248,  2.6615,  3.6154,  ...,  2.2346,  0.0211,  0.2310],\n",
      "         [-0.3420,  4.3324,  0.6619,  ...,  1.5645,  1.3461,  0.3359],\n",
      "         [ 3.0530,  2.8983,  2.4913,  ..., -0.6784, -2.1746,  0.4604]],\n",
      "\n",
      "        [[-1.2555,  4.3146,  1.0621,  ..., -0.9031, -3.2124,  1.0194],\n",
      "         [-1.8580,  3.3886, -1.3947,  ...,  3.2414, -3.8878,  0.8742],\n",
      "         [-2.1807,  2.9099,  2.9216,  ...,  3.9311, -1.1293,  0.5376],\n",
      "         ...,\n",
      "         [ 0.4995, -0.1362,  1.6128,  ...,  4.9181, -3.7591,  0.3999],\n",
      "         [-0.1896,  2.5756,  0.2065,  ...,  4.1975, -1.3033, -0.0813],\n",
      "         [-2.3787, -0.5187,  0.9549,  ...,  3.8166, -3.7047,  0.1514]],\n",
      "\n",
      "        [[-0.2118, -1.0157, -0.7257,  ...,  3.9676, -0.3843,  4.3723],\n",
      "         [-2.7645,  1.0665, -1.7705,  ...,  2.9752,  3.2110,  5.2790],\n",
      "         [-2.1193,  1.6865, -0.1489,  ...,  3.1497,  0.6186,  2.6645],\n",
      "         ...,\n",
      "         [ 3.1619,  1.3557,  1.8563,  ...,  2.7084,  0.9460,  1.2595],\n",
      "         [-1.3180,  1.3369,  0.8518,  ...,  5.1055, -1.5023, -0.1376],\n",
      "         [-3.5317,  1.0057,  2.0049,  ...,  4.8510, -1.3036,  1.5161]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.3789, -1.6337, -0.2267,  ...,  2.7716, -2.1879,  2.2994],\n",
      "         [ 2.3879,  0.7633, -1.1589,  ...,  4.4500, -2.1228,  0.1375],\n",
      "         [ 3.8502,  2.8784, -0.0928,  ...,  5.7736, -3.2948, -1.7036],\n",
      "         ...,\n",
      "         [-0.1341,  3.0120,  1.9406,  ...,  3.8621, -3.0651, -1.2877],\n",
      "         [ 2.3578,  1.1524,  1.0155,  ...,  4.2057,  0.0066, -0.5482],\n",
      "         [-1.9153,  1.9298,  3.6604,  ...,  5.2263, -0.7229, -0.1661]],\n",
      "\n",
      "        [[-0.4603,  2.4225,  4.1216,  ...,  5.2468, -1.3347,  0.5434],\n",
      "         [-0.0749,  3.7133,  2.7207,  ...,  5.1215, -1.5570,  0.4509],\n",
      "         [ 0.6484,  5.1314,  0.7476,  ...,  1.0672, -3.6193,  0.2647],\n",
      "         ...,\n",
      "         [-0.9043,  1.2248,  3.5068,  ...,  1.4938, -1.3741,  0.4832],\n",
      "         [ 1.4116,  0.2002,  1.6684,  ...,  2.0038, -2.0983, -1.2435],\n",
      "         [-2.7962,  2.7161, -1.2817,  ...,  3.2030,  0.3463, -0.0733]],\n",
      "\n",
      "        [[-0.4339,  0.7173,  1.4170,  ...,  2.9189,  1.3805,  1.5022],\n",
      "         [ 2.1088,  2.7246,  3.0801,  ...,  1.7535,  0.6158,  0.4519],\n",
      "         [ 3.0768,  2.2780,  1.0359,  ...,  0.7978,  1.3082,  1.6706],\n",
      "         ...,\n",
      "         [ 0.6717,  0.8435, -0.6803,  ...,  2.2367, -0.0209,  0.5033],\n",
      "         [ 2.8197,  1.3479,  2.9524,  ...,  3.6487,  1.2068,  0.0274],\n",
      "         [ 0.7328,  1.5470,  1.2439,  ...,  3.9280, -1.2332,  0.7243]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.masked_attention = MultiHeadedAttention(masked=True)\n",
    "\t\tself.norm1 = nn.LayerNorm(EMBEDDING_DIMENSIONS)\n",
    "\t\tself.cross_attention  = MultiHeadedAttention()\n",
    "\t\tself.norm2 = nn.LayerNorm(EMBEDDING_DIMENSIONS)\n",
    "\t\tself.feed_forward = FeedForward()\n",
    "\t\tself.norm3 = nn.LayerNorm(EMBEDDING_DIMENSIONS)\n",
    "\n",
    "\tdef forward(self, data, encoder_output):\n",
    "\t\tattention_vectors = self.masked_attention(data)\n",
    "\t\tnormalised = self.norm1(attention_vectors) + data\n",
    "\t\tcross_attention = self.cross_attention(normalised, encoder_output=encoder_output)\n",
    "\t\tnormalised = self.norm2(cross_attention) + normalised\n",
    "\t\tlinear = self.feed_forward(normalised)\n",
    "\t\tnormalised = self.norm3(linear) + normalised\n",
    "\n",
    "\t\treturn normalised\n",
    "\n",
    "\n",
    "test = torch.randn(size=(BATCH_SIZE, SEQUENCE_LENGTH, EMBEDDING_DIMENSIONS))\n",
    "encoder_output = torch.randn(size=(BATCH_SIZE, SEQUENCE_LENGTH, QKV_DIMENSIONS))\n",
    "test_module = Decoder()\n",
    "print(test_module(test, encoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 106]) torch.Size([128, 106])\n",
      "torch.Size([128, 6401])\n"
     ]
    }
   ],
   "source": [
    "class Transformer(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.cherokee_embeddings = nn.Embedding(cherokee_vocab_size, EMBEDDING_DIMENSIONS)\n",
    "\t\tself.cherokee_positional_encodings = nn.Embedding(SEQUENCE_LENGTH, EMBEDDING_DIMENSIONS)\n",
    "\t\tself.encoders = [Encoder() for _ in range(ENCODERS)]\n",
    "\t\tself.decoders = [Decoder() for _ in range(DECODERS)]\n",
    "\t\tself.english_embeddings = nn.Embedding(english_vocab_size, EMBEDDING_DIMENSIONS)\n",
    "\t\tself.english_positional_encodings = nn.Embedding(SEQUENCE_LENGTH, EMBEDDING_DIMENSIONS)\n",
    "\t\tself.linear   = nn.Linear(SEQUENCE_LENGTH, english_vocab_size) \n",
    "\n",
    "\tdef forward(self, source, target_context):\n",
    "\t\tencoder_output = self.cherokee_embeddings(source) + self.cherokee_positional_encodings(torch.tensor([i for i in range(SEQUENCE_LENGTH)]))\n",
    "\t\tfor encoder in self.encoders:\n",
    "\t\t\tencoder_output = encoder(encoder_output)\n",
    "\n",
    "\t\tdecoder_output = self.english_embeddings(target_context) + self.english_positional_encodings(torch.tensor([i for i in range(SEQUENCE_LENGTH)]))\n",
    "\n",
    "\t\tfor decoder in self.decoders:\n",
    "\t\t\tdecoder_output = decoder(decoder_output, encoder_output=encoder_output)\n",
    "\t\t\t\n",
    "\t\tdecoder_output = torch.mean(decoder_output, dim=-1)\n",
    "\t\tlogits = self.linear(decoder_output)\n",
    "\t\tprobabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "\t\treturn probabilities\n",
    "\t\n",
    "cherokee_input = torch.randint(low=0, high=cherokee_vocab_size-1, size=(BATCH_SIZE, SEQUENCE_LENGTH,))\n",
    "target_context = torch.zeros(size=(BATCH_SIZE, SEQUENCE_LENGTH,), dtype=int)\n",
    "print(cherokee_input.shape, target_context.shape)\n",
    "model = Transformer()\n",
    "print(model(cherokee_input, target_context).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\tdef __init__(self, learning_rate, model):\n",
    "\t\tself.model = model\n",
    "\t\tself.learning_rate = learning_rate\n",
    "\t\tself.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\tdef get_batch(self, english, cherokee, probabilities):\n",
    "\t\tindexes = torch.randint(0, english.shape[0], size=(BATCH_SIZE,))\n",
    "\t\tenglish  = torch.stack([english[i] for i in indexes])\n",
    "\t\tcherokee = torch.stack([cherokee[i] for i in indexes])\n",
    "\t\tprobabilities = torch.stack([probabilities[i] for i in indexes])\n",
    "\n",
    "\t\treturn english, cherokee, probabilities\n",
    "\t\n",
    "\tdef pass_batch(self, english, cherokee, probabilities):\n",
    "\t\tenglish, cherokee, probabilities = self.get_batch(english, cherokee, probabilities)\n",
    "\t\tlogits = self.model(cherokee, english)\n",
    "\t\tloss = nn.functional.cross_entropy(logits, probabilities.float())\n",
    "\n",
    "\t\treturn logits, loss\n",
    "\t\n",
    "\tdef train(self, epochs):\n",
    "\t\tfor i in range(epochs):\n",
    "\t\t\tlogits, loss = self.pass_batch(train_english, train_cherokee, train_probabilities)\n",
    "\t\t\tself.optimizer.zero_grad(set_to_none=True)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tself.optimizer.step()\n",
    "\n",
    "\t\t\t#for param in self.model.parameters():\n",
    "\t\t\t#\tprint(param.grad.data.sum())\n",
    "\t\t\t\n",
    "\t\t\tprint(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.7642, grad_fn=<DivBackward1>)\n",
      "tensor(8.7630, grad_fn=<DivBackward1>)\n",
      "tensor(8.7401, grad_fn=<DivBackward1>)\n",
      "tensor(8.7269, grad_fn=<DivBackward1>)\n",
      "tensor(8.7279, grad_fn=<DivBackward1>)\n",
      "tensor(8.7224, grad_fn=<DivBackward1>)\n",
      "tensor(8.6864, grad_fn=<DivBackward1>)\n",
      "tensor(8.7098, grad_fn=<DivBackward1>)\n",
      "tensor(8.6864, grad_fn=<DivBackward1>)\n",
      "tensor(8.6707, grad_fn=<DivBackward1>)\n",
      "tensor(8.7176, grad_fn=<DivBackward1>)\n",
      "tensor(8.7176, grad_fn=<DivBackward1>)\n",
      "tensor(8.7176, grad_fn=<DivBackward1>)\n",
      "tensor(8.7176, grad_fn=<DivBackward1>)\n",
      "tensor(8.7176, grad_fn=<DivBackward1>)\n",
      "tensor(8.6317, grad_fn=<DivBackward1>)\n",
      "tensor(8.6864, grad_fn=<DivBackward1>)\n",
      "tensor(8.7176, grad_fn=<DivBackward1>)\n",
      "tensor(8.7098, grad_fn=<DivBackward1>)\n",
      "tensor(8.7020, grad_fn=<DivBackward1>)\n",
      "tensor(8.7176, grad_fn=<DivBackward1>)\n",
      "tensor(8.6942, grad_fn=<DivBackward1>)\n",
      "tensor(8.7098, grad_fn=<DivBackward1>)\n",
      "tensor(8.6864, grad_fn=<DivBackward1>)\n",
      "tensor(8.6942, grad_fn=<DivBackward1>)\n",
      "tensor(8.6942, grad_fn=<DivBackward1>)\n",
      "tensor(8.6629, grad_fn=<DivBackward1>)\n",
      "tensor(8.6942, grad_fn=<DivBackward1>)\n",
      "tensor(8.6942, grad_fn=<DivBackward1>)\n",
      "tensor(8.6785, grad_fn=<DivBackward1>)\n",
      "tensor(8.6864, grad_fn=<DivBackward1>)\n",
      "tensor(8.6551, grad_fn=<DivBackward1>)\n",
      "tensor(8.6864, grad_fn=<DivBackward1>)\n",
      "tensor(8.7254, grad_fn=<DivBackward1>)\n",
      "tensor(8.7020, grad_fn=<DivBackward1>)\n",
      "tensor(8.6317, grad_fn=<DivBackward1>)\n",
      "tensor(8.6942, grad_fn=<DivBackward1>)\n",
      "tensor(8.7098, grad_fn=<DivBackward1>)\n",
      "tensor(8.7020, grad_fn=<DivBackward1>)\n",
      "tensor(8.6864, grad_fn=<DivBackward1>)\n",
      "tensor(8.7020, grad_fn=<DivBackward1>)\n",
      "tensor(8.6864, grad_fn=<DivBackward1>)\n",
      "tensor(8.6942, grad_fn=<DivBackward1>)\n",
      "tensor(8.7332, grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Shayaan/Desktop/code/en-ch-nmt/main.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Shayaan/Desktop/code/en-ch-nmt/main.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m Transformer()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Shayaan/Desktop/code/en-ch-nmt/main.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, model\u001b[39m=\u001b[39mmodel)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Shayaan/Desktop/code/en-ch-nmt/main.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(\u001b[39m100\u001b[39;49m)\n",
      "\u001b[1;32m/Users/Shayaan/Desktop/code/en-ch-nmt/main.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Shayaan/Desktop/code/en-ch-nmt/main.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m logits, loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpass_batch(train_english, train_cherokee, train_probabilities)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Shayaan/Desktop/code/en-ch-nmt/main.ipynb#X20sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad(set_to_none\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Shayaan/Desktop/code/en-ch-nmt/main.ipynb#X20sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Shayaan/Desktop/code/en-ch-nmt/main.ipynb#X20sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Shayaan/Desktop/code/en-ch-nmt/main.ipynb#X20sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m#for param in self.model.parameters():\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Shayaan/Desktop/code/en-ch-nmt/main.ipynb#X20sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m#\tprint(param.grad.data.sum())\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Transformer()\n",
    "trainer = Trainer(learning_rate=0.2, model=model)\n",
    "trainer.train(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
